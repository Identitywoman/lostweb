Centralized "Social Media" Is Broken By Design
==============================================

There is an entire subcategory of writing now about how Social Media is terrible.  Most point to software features or corporate negligence or even malfeasance.  This entire site actually takes a different tack, namely, that Centralized "Social Media" Is Harmful By Design. (Link)

  * https://www.buzzfeed.com/charliewarzel/a-honeypot-for-assholes-inside-twitters-10-year-failure-to-s

  * Bandwith Scarcity has transformed into Attention Scarcity
    - Quote from scott: "back at MS we fully expected p2p to take off" (see evernote)

    * The idea of "publication" is a fundamental construct that is outside of human brainstem adaptation for communication.  Our firmware has no evolutionary mechanism for dealing with asymmetric comms channel.  We are used to being able to talk back to anything that talked to us.  Only on the last few hundred years has widespread literacy given rise to the possibility of humans becoming transmission media for ideas.
    A sheet of paper posted on a wall in the town square has the same root social dynamic as Trump tweeting to millions of people.
    We have to deprogram people to not be receivers of mere broadcast.  This requires training them in attention management.

    * Fake news, Information diabetes, are all different dimensions of the same core problem

    * The fact that people talk about it as "attention economy" is itself problematic.  Attention is a fundamental aspect of human independent agency.  To treat it as a natural resource to somehow be mined, molded, traded is no less immoral than all previous forms of human servitude.

  * We cannot leave Net Neutrality up to the transport companies.  More broadly, we currently live under a tyranny of "Code Is Law": 

    If human information dynamics are bound to conform to the dynamics of digital, connected packet transfer, in a hierarchical network of insecure computers, then we are inherently doomed. We are slave to coders, chipmakers, and those who control them.
    
    So the programme of effort must necessarily be about creating computational and communications infrastructure that *can* be made to conform to the needs of natural human interaction, and thus cultural and social law.
    
    A key aspect of this is that the communications and information tools need to allow for groups and cultures to evolve their values over time. If they are coded into the protocols, or frozen into the structure of a silicon valley's accidental rise to economic success, then they impose on us in ways that we cannot control.
    
    Lastly, real Laws are not Value Neutral.  There is no society of 300 million people.  There can be a network of societies, or overlapping layers of cultures.  But a sense of "community", whose values are writable by its participants, does not scale past to that size.


Centralized Social Media Sites Are Attention Markets
----------------------------------------------------

Consider the primary difference between Facebook and WhatsApp or any "group messaging" system (even group SMS): there is no "global trending / recommended" concept for the latter.  FB and Twitter, however, want to pretend to offer a global view.  This seems like a minor feature, but is actually the central, lynchpin issue for all of this.

Centralized social media platforms accrue users into a single site that ranks by popularity. Anytime you create a *single* site, and you get eyeballs onto that site, you have created an attention platform.  It's not a broadcast platform, it's an absorption platform.  And that creates a scarcity which commercial players will exploit for advertising, and individuals will exploit for social clout.  See https://www.reddit.com/r/HailCorporate/ for how this affects Reddit, which otherwise has a very organic sort of community.

Consider: There's no way to "experience Reddit" except as a website.  This architectural affordance naturally guides engineers to designing and making features that are straightforward and make sense as a *site*, a single place people go to.  The chatter, organic discourse, etc. that happen on it are bolted-on afterwards.

An alternative model is to create platforms for conversation and chatter from which higher-level views can be cohered.  Reddit's [/r/place](reddit.com/r/place) experiment was a lovely example of how giving people total control over what they create together, even with a mechanic as simple as just coloring a pixel, could result in emergent order and community.  Part of this was that they needed to see the whole pattern reflected back to them. 

  *As an aside:* The lag time between when you do an act, and when you can see the result, and also the directness of connection between your act and the end result, both affect your "relationship" and feeling of connectedness with the community of creators.  These are both important parameters to experiment with.  Social pixel coloring is super simple and super easy to understand.  But if we were to feed our ideas into something more nonlinear, like a convnet that's been trained on a particular genre of stories?  Or a newsbot that absorbs all the world's newspapers, and we tell it what we're interested in?


So in the discussion of centralization vs. de-centralization, it's important to distinguish between *centralization of transport infrastructure* and *aggregation of attention*.

--------

If any of these were actual platforms for socialization between people, then they would have devised metrics that correspond to growing trust, fulfillment, and other qualities of actual interpersonal relationships.  Instead, almost all of them measure things like “engagement”, “time on site”, “click through”, “number of shares/likes/posts/etc.”.  These are measurements of how much time you are sapping from people, and how successfully you’ve co-opted their brainstem programming for tribal affiliation to watch ads on your website.

Fundamentally, technology providers have to cover their costs, and make some profit.  Even a non-profit has to cover its costs.  The structure of the internet at the time when social media first emerged forced Facebook to aggregate traffic and centralize the entire social graph on its servers.  It also had to pay for storage of images and all the inbound bandwidth.  So to cover the costs, the most obvious monetization avenue for it (that wouldn't hurt adoption) was via advertising.  Once it got hooked on that kind of revenue, it's impossible to put down the crack pipe.

One could imagine a Facebook that was monetized entirely differently, and optimized for its users' mental health and social positivity.  It could simply charge for advanced features, like sub-accounts for children with sophisticated content and friend list controls, or pay-per-message Direct Messaging like LinkedIn.  More advanced control over one's profile page, and additional vanity options, could help differentiate the paying users from the non-paying ones and provide for virtue signaling.  Facebook could facilitate celebrity AMAs, do sponsored FB Live broadcasts, charge commissions for Verified Seller status for repeat sellers in Marketplace, etc. etc.  And lest you think that this is crazy talk, look at Reddit: they created a way for users to voluntarily pay via Reddit Gold.

At the end of the day, Facebook's ad platform makes about $5 per user per year.  They could just provide an option for users to pay that directly, and shut off all participation in advertising, tracking, etc.  If enough people did that, it would have neutered the Russian election propaganda attack.  So when your children ask about the 2016 election, you can tell them that we sold our democracy for $5 a head.

Despite all this hating on Facebook and Twitter, I want to make it clear that they are not the full problem.  They are merely the American manifestations of the problem.  Even if both were to disappear, it does nothing to help the cause of liberté and fraternité in China, which has different tech.  If we're going to go through the trouble of solving this problem, we should build a universally useful information system.



Content Policing Is the Inevitable Cost of Success At Scale
-----------------------------------------------------------

  * Moderators are only need when comms channels become broadcast platforms. 
    If a robust identity system is implemented (even with a limited anonymity system with karma), then social dynamics govern behavior.
    In fact this is a root problem with existing tech: it is structurally incapable of being governed by physical space social dynamics, including shame as well as kudos.
  
  * When data/content is centralized, content has to get approved.  Content by itself does not have a "rating". A rating or even legality is the result of interaction of content with the social field around it.
  
    * (triggered by a notification from Google after I added some public photos that my photos will be visible after they are approved). If we have P2P content networks, then it's people and their credibility and netkarma that gets modulated, by the network of people around them.

    * https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2

      "But both stories take at face value YouTube’s assertions that these results are incredibly rare and quickly removed: assertions utterly refuted by the proliferation of the stories themselves, and the growing number of social media posts, largely by concerned parents, from which they arise.”

      Every communications medium is also a substrate for the reinforcement and evolution of *cultural values*.  A communications medium whose business model is monetization of attention tends to fall into the trap of converting into a broadcast medium (and giving users a lottery mechanic to earn social currency - “going viral”).  And once something is a broadcast medium, it inevitably takes on the task of being a tastemaker.

      This is not something new that the Internet has brought about.  Hollywood went through this - https://en.wikipedia.org/wiki/Film_censorship_in_the_United_States  Starting with enlisting local police chiefs to censor content, it evolved into the MPAA and the Production Code.  Joseph Breen and the Hays Code (1934-1960s).

  * Centralized platforms create a *fake commons* and then have to police values among those commons. This exacerbates an "offense culture" and throw millions of people who share no values into a single battleground to fight for dominance, mob/swarm individuals of other tribes, etc.  No one asked for this.  It's egregiously, criminally bad software and user interface design.

  * Echo chambers are the naturally consequence of dissent-free zones

    One can create such zones by repulsion or attraction.

    Modern online social platforms fall into this second category of failure, almost by design.  In exploiting the unlimited bandwidth of the internet, they demonstrated that the scarcity of certain kinds of civic spaces is a feature and not a bug: they force is to devote some slice of our attention to people and things and ideas outside of our comfort zone. Each of us then becomes a little mixing chamber for different ideas and experiences, rather than simply becoming an ever finer-tuned resonator for some increasingly polarizing external signal.  (We subject ourselves to Flanderization.)
    This is another instance of why privacy is so important.

  * Ricky Gervais on Oxford Union: "Twitter more and more, gives people a way to create their own filter bubble and has led to a sort of conceit around, “My opinion is as good as your opinion”, which then when a bunch of idiots can find each other and band together, “my opinion is as good as your fact”. Twitter and FB have allowed idiots to unite, and become a social movement.


Gamifying All the Wrong Things
------------------------------

  * attention gaming is the biggest public mental health crisis of our time [see evernote]

  * "Going Viral" - The fact that something can "go viral" is an indicator of a failure mode. Bad information systems help metastisize.

    https://www.washingtonpost.com/posteverything/wp/2016/11/18/my-fake-news-list-went-viral-but-made-up-stories-are-only-part-of-the-problem/

  * Facebook metastasis: http://www.tandfonline.com/doi/full/10.1080/1369118X.2017.1418406
    "Although anti-vaccination networks on Facebook are large and global in scope, the comment activity sub-networks appear to be ‘small world’. This suggests that social media may have a role in spreading anti-vaccination ideas and making the movement durable on a global scale."


We Need a Platform for Intersubjectivity
----------------------------------------

  * "we need a platform for intersubjectivity" [see evernote]

  * Why does the question of morality arise when it comes to API design? [see evernote]

  * Taking a more philosophical approach: Centralized Social Media has created a medium where intersubjectivity creates precipitates/artifacts with disorienting frequency.  This is what Scott Adams gets wrong about Trump: They marvel at the "stupidity" of literalists on the left (and right) who merely receive the waves of media messaging and respond to them.  Stimulus-response, you stupid libtard - don't you know you're being trolled?

    Facebook, Twitter drive all their revenue from monetizing attention.  They can only do that because they are gateways.  (Compare with web portal business model from the 90s)

    Their only hope for salvation of to use their machine learning algorithms to find ways to help bring people closer together, by pairing or guiding their interactions with other users and content that are "close" to being palatable to a particular user, but will not repel them.  They have to fully step into their roles as first class components of a national, political conversation, not only because that's what everyone is using them for, but also because this is the fate of any communications medium.  The only actual choice is whether or not you're going to be a good political medium; not whether you are going to be political.  Twitter can no more choose to be apolitical than Donald Trump can choose to not govern.  I'm both cases, it's a dereliction of duty.

    If you're going to build a national messaging platform, then it's on you to enforce content standards at the level of truthfulness and intent. You can't be the sole source vendor of the entire counts food and pretend you don't have a duty to label its nutritional contents.  

    If FedEx started shipping mailbombs between people, how many nanoseconds would elapse before they shut everything down to figure out what happened?  Infobombs are worse, because the damage is long term and structural and invisible.


Further Reading
---------------

 * [Authoritarians Distract Rather than Debate](http://marginalrevolution.com/marginalrevolution/2017/01/authoritarians-distract-rather-debate.html): 
   Using attention space as a battle space. The aggregation of attention into central platforms reduces the total amount of social interaction, and provides a very juicy target for misinformation and disinformation.

